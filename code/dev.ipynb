{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import gc\n",
    "pd.set_option('display.max_columns', 1_00)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH_ADMISSION = '../raw_data/IDs_mapping.csv'\n",
    "RAW_DATA_PATH_DIABETES  = '../raw_data/diabetic_data.csv'\n",
    "DATA_PATH = '../data'\n",
    "DATA_PATH_MAP = DATA_PATH + '/map_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = pd.read_csv(RAW_DATA_PATH_ADMISSION)\n",
    "df = pd.read_csv(RAW_DATA_PATH_DIABETES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TIDY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Add descriptions to main dataframe `df` and remove ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# admission types\n",
    "df_admission = df_map[:8]\n",
    "df_discharge = df_map[10:40].rename(columns = {'admission_type_id':'discharge_disposition_id'})\n",
    "df_admission_source = df_map[42:66].rename(columns = {'admission_type_id': 'admission_source_id'})\n",
    "df_admission.iloc[:,0] = df_admission.iloc[:,0].astype(int)\n",
    "df_discharge.iloc[:,0] = df_discharge.iloc[:,0].astype(int)\n",
    "df_admission_source.iloc[:,0] = df_admission_source.iloc[:,0].astype(int)\n",
    "df_admission.rename(columns = {'description': 'admission_type'},inplace=True)\n",
    "df_discharge.rename(columns = {'description': 'discharge_disposition'},inplace=True)\n",
    "df_admission_source.rename(columns = {'description': 'admission_source'},inplace=True)\n",
    "\n",
    "# clean columns in df\n",
    "df.columns = list(map(lambda i: i.lower().replace('-','_'), df.columns))\n",
    "\n",
    "# merge with maps ids\n",
    "df = df.merge(df_admission, on = 'admission_type_id', how='left')\n",
    "df = df.merge(df_discharge, on = 'discharge_disposition_id', how='left')\n",
    "df = df.merge(df_admission_source, on = 'admission_source_id', how='left')\n",
    "\n",
    "# remove description columns\n",
    "df.drop(['admission_type_id', 'discharge_disposition_id', 'admission_source_id'], axis=1, inplace=True)\n",
    "\n",
    "# drop duplicates\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# save\n",
    "df.to_csv(os.path.join(DATA_PATH, 'diabetes_tidy.csv'), index=False)\n",
    "\n",
    "# free memory\n",
    "del df_discharge, df_admission, df_admission_source\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create a dataset in DATA_PATH_MAP with all map dataframe to map description and ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_id_map(df, column):\n",
    "    aux = pd.DataFrame(df[column].value_counts().index, columns=[column])\n",
    "    aux[f'{column}_id'] = list(range(1,len(aux)+1))\n",
    "    return aux\n",
    "\n",
    "def create_maps(df, columns, data_path):\n",
    "    map_dict = {i:df_id_map(df,i) for i in columns}\n",
    "    # save map dict\n",
    "    for k, v in map_dict.items():\n",
    "        v.to_csv(os.path.join(data_path, f'{k}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_maps(df, list(df.select_dtypes('object').columns), DATA_PATH_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Apply the mapping system created to the main dataframe `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_map_id(df, data_path):\n",
    "    data_maps = list(map(lambda i: os.path.join(data_path,i),os.listdir(data_path)))\n",
    "    for i in data_maps:\n",
    "        aux = pd.read_csv(i)\n",
    "        id_col = list(filter(lambda i:i.endswith('_id'), aux.columns))[0]\n",
    "        on_col = list(set(aux.columns).difference(set([id_col])))[0]\n",
    "        aux[id_col] = aux[id_col].astype(int)\n",
    "        df = df.merge(aux,on=on_col, how='left')\n",
    "        df.drop(on_col, axis=1, inplace = True)\n",
    "        df[id_col] = df[id_col].fillna(0)\n",
    "        df[id_col] = df[id_col].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy = apply_map_id(df, DATA_PATH_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encounter_id                   int64\n",
       "patient_nbr                    int64\n",
       "time_in_hospital               int64\n",
       "num_lab_procedures             int64\n",
       "num_procedures                 int64\n",
       "num_medications                int64\n",
       "number_outpatient              int64\n",
       "number_emergency               int64\n",
       "number_inpatient               int64\n",
       "number_diagnoses               int64\n",
       "rosiglitazone_id               int64\n",
       "acetohexamide_id               int64\n",
       "a1cresult_id                   int64\n",
       "citoglipton_id                 int64\n",
       "age_id                         int64\n",
       "gender_id                      int64\n",
       "glipizide_metformin_id         int64\n",
       "miglitol_id                    int64\n",
       "metformin_id                   int64\n",
       "tolbutamide_id                 int64\n",
       "nateglinide_id                 int64\n",
       "acarbose_id                    int64\n",
       "admission_type_id              int64\n",
       "pioglitazone_id                int64\n",
       "weight_id                      int64\n",
       "readmitted_id                  int64\n",
       "troglitazone_id                int64\n",
       "glyburide_id                   int64\n",
       "chlorpropamide_id              int64\n",
       "insulin_id                     int64\n",
       "diabetesmed_id                 int64\n",
       "metformin_rosiglitazone_id     int64\n",
       "diag_1_id                      int64\n",
       "diag_2_id                      int64\n",
       "change_id                      int64\n",
       "diag_3_id                      int64\n",
       "payer_code_id                  int64\n",
       "glimepiride_pioglitazone_id    int64\n",
       "medical_specialty_id           int64\n",
       "glipizide_id                   int64\n",
       "examide_id                     int64\n",
       "discharge_disposition_id       int64\n",
       "race_id                        int64\n",
       "repaglinide_id                 int64\n",
       "max_glu_serum_id               int64\n",
       "admission_source_id            int64\n",
       "tolazamide_id                  int64\n",
       "glyburide_metformin_id         int64\n",
       "metformin_pioglitazone_id      int64\n",
       "glimepiride_id                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tidy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it\n",
    "df_tidy.to_csv(os.path.join(DATA_PATH, 'diabetes_integers.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Remove some columns with high missing values [`weight`, `payer_code`, `medical_specialty`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>race</td>\n",
       "      <td>0.022336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weight</td>\n",
       "      <td>0.968585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>payer_code</td>\n",
       "      <td>0.395574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>medical_specialty</td>\n",
       "      <td>0.490822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diag_1</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diag_2</td>\n",
       "      <td>0.003518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>diag_3</td>\n",
       "      <td>0.013983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            variable     value\n",
       "0               race  0.022336\n",
       "1             weight  0.968585\n",
       "2         payer_code  0.395574\n",
       "3  medical_specialty  0.490822\n",
       "4             diag_1  0.000206\n",
       "5             diag_2  0.003518\n",
       "6             diag_3  0.013983"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = {i : (df[i] == '?').mean() for i  in df.columns}\n",
    "missing_values = {k:v for k,v in missing_values.items() if v>0}\n",
    "pd.DataFrame.from_dict([missing_values]).melt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy = df_tidy.drop(['weight_id', 'payer_code_id', 'medical_specialty_id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Categorical values\n",
    "As we can see in the next picture, the univariant effeect of categorical variables has no impact to clasiffy an observation as readmitted or not. The frequentist analysis of those categories shows that the percentage of each value of each category are quite close to be 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/categorical_univariant_effect.png\" width=800 height=800 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Numerical values\n",
    "Those density plots are easy to explain. the variables have negative imapact, I mean, the more the worse, the more medication yo need, the more prob. to be readmitted, the more time in hostpital, the more prob. to be readmitted. \n",
    "So when the X increase the density graph green (be readmitted) is higher than de density of red (not). \n",
    "But as we can see those numerical variables has not much power to classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/density_numerics.png\" width=800 height=800 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 High cardinality categories\n",
    "When categorical variables have many categories, we call them high cardinality categorical variables. It is usually difficult to work with them, a trick is to find that category that hides more information, that is, that has more predictive capacity. For this we can use the standard deviation in the frequency of appearance in readmitted (1) or not (0) and we see that there are certain categories with a lot of classification capacity. Good news. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/high_categorical.png\" width=800 height=800 />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
